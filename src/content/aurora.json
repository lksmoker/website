{
  "meta": {
    "title": "Aurora",
    "description": "Aurora is a conceptual approach to building software through conversation."
  },
  "sections": {
    "whatItIs": [
      "Aurora is a conceptual approach to building software through conversation.",
      "It’s centered on the idea that people should be able to express intent in natural language, see clear, inspectable feedback, and guide systems through a shared understanding."
    ],
    "whyItMatters": [
      "Software creation today is fragmented across documents, tools, and communication channels.",
      "Aurora explores a more natural path — one where clarity, reasoning, and understanding are part of the process itself."
    ],
    "origin": [
      "After building several apps with AI assistance, I ran into the same frustrations many others have described: bugs that didn’t make sense, feedback loops that went nowhere, and long chains of fixes that seemed disconnected from what I actually meant. Tools are improving — some models now sit right next to your code — but the process still feels murky and overly complicated.",
      "I noticed a pattern repeating itself: a human speaks to an AI, the AI interprets the human’s intention, and then translates that understanding into Python, JavaScript, HTML, and so on. Each step is another layer where meaning can drift. We’re forcing AI to operate inside architectures that were never designed with AI in mind.",
      "And that raised a question: what if we didn’t need all those layers at all? What if AI could work in an environment native to its reasoning — one where human intent could translate directly into software without detouring through multiple languages and frameworks?",
      "What if the conversation was the development environment?",
      "As Aurora took shape, I began seeing the same challenges reflected in emerging articles and research, validating my intuition and direction:"
    ],
    "signals": [
      {
        "id": "ai-coding-tools-observability",
        "source": "ZDNET — \"Why AI coding tools like Cursor and Replit are doomed — and what comes next\"",
        "href": "https://www.zdnet.com/article/why-ai-coding-tools-like-cursor-and-replit-are-doomed-and-what-comes-next/",
        "idea": "Raises a blunt question: if AI coding tools are just thin wrappers around foundation models, how will they survive — and where will real differentiation come from?",
        "auroraAnswer": "Aurora treats observability and understanding as the differentiator. Instead of competing on code generation alone, it focuses on making every change explainable: who asked for it, why it exists, and how it fits into the larger system."
      },
      {
        "id": "mit-legible-modular-software",
        "source": "MIT News — \"MIT researchers propose a new model for legible, modular software\"",
        "href": "https://news.mit.edu/2025/mit-researchers-propose-new-model-for-legible-modular-software-1106",
        "idea": "Argues that software should be structured so both humans and large language models can read, reason about, and safely extend it.",
        "auroraAnswer": "Aurora takes a complementary approach: instead of reshaping code to be a little more AI-friendly, it imagines a kernel where human intent, system facts, and effects are first-class concepts the AI can work with directly."
      },
      {
        "id": "ai-assistants-bigger-flaws",
        "source": "BankInfoSecurity — \"Coding With AI Assistants: Faster Performance, Bigger Flaws\"",
        "href": "https://www.bankinfosecurity.com/coding-ai-assistants-faster-performance-bigger-flaws-a-29375",
        "idea": "Finds that AI coding assistants can speed up development while also introducing harder-to-see security and reliability issues.",
        "auroraAnswer": "Aurora’s emphasis on traceability is one answer to this tension: if every AI-proposed change carries a visible rationale and causal trail, teams have a better shot at reviewing, trusting, or rolling back what the system produces."
      }
    ],
    "whatItIsNot": [
      "Not a no-code tool",
      "Not an IDE",
      "Not an assistant",
      "Not a rules engine",
      "Not a schema or protocol",
      "Not a product announcement"
    ],
    "howItWorksSafe": [
      "Aurora uses a conversational workflow: people describe what they’re trying to achieve, the system reflects and refines its understanding, and both work together to shape the result.",
      "This is a conceptual framing, without revealing internal structures or technical mechanisms."
    ],
    "futureDirection": [
      "Aurora will evolve gradually, beginning with narrative descriptions and eventually expanding to high-level examples.",
      "Technical details, internals, and system mechanics will remain undisclosed."
    ],
    "cta": "If you’re interested in the ideas behind Aurora, I’m open to high-level conversations about the concepts and vision."
  }
}
